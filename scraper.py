# scraper.py - ‡¶´‡¶ø‡¶ï‡ßç‡¶∏‡¶° ‡¶ì‡¶Ø‡¶º‡ßá‡¶¨ ‡¶∏‡ßç‡¶ï‡ßç‡¶∞‡ßá‡¶™‡¶ø‡¶Ç ‡¶∏‡¶ø‡¶∏‡ßç‡¶ü‡ßá‡¶Æ
import requests
from bs4 import BeautifulSoup
import json
import time
import re
from datetime import datetime

class MovieScraper:
    def __init__(self, website_url):
        self.website_url = website_url
        self.movies_data = []
    
    def scrape_movies(self):
        """‡¶ì‡¶Ø‡¶º‡ßá‡¶¨‡¶∏‡¶æ‡¶á‡¶ü ‡¶•‡ßá‡¶ï‡ßá ‡¶Ü‡¶∏‡¶≤ ‡¶Æ‡ßÅ‡¶≠‡¶ø ‡¶°‡¶æ‡¶ü‡¶æ ‡¶∏‡ßç‡¶ï‡ßç‡¶∞‡ßá‡¶™ ‡¶ï‡¶∞‡¶¨‡ßá"""
        try:
            print(f"üîç ‡¶∏‡ßç‡¶ï‡ßç‡¶∞‡ßá‡¶™‡¶ø‡¶Ç ‡¶∂‡ßÅ‡¶∞‡ßÅ: {self.website_url}")
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            response = requests.get(self.website_url, headers=headers, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            print("‚úÖ ‡¶ì‡¶Ø‡¶º‡ßá‡¶¨‡¶∏‡¶æ‡¶á‡¶ü ‡¶≤‡ßã‡¶° ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá")
            
            # ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶∏‡¶æ‡¶á‡¶ü‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶∏‡¶†‡¶ø‡¶ï elements ‡¶ñ‡ßÅ‡¶Å‡¶ú‡¶¨‡ßá
            # Test ‡¶•‡ßá‡¶ï‡ßá ‡¶¶‡ßá‡¶ñ‡¶≤‡¶æ‡¶Æ: 96 div, 103 links
            all_links = soup.find_all('a')
            print(f"üîó ‡¶Æ‡ßã‡¶ü ‡¶≤‡¶ø‡¶Ç‡¶ï: {len(all_links)} ‡¶ü‡¶ø")
            
            movie_count = 0
            
            # ‡¶∂‡ßÅ‡¶ß‡ßÅ relevant links filter ‡¶ï‡¶∞‡¶¨‡ßá
            for link in all_links:
                try:
                    href = link.get('href', '')
                    link_text = link.text.strip()
                    
                    # ‡¶∂‡ßÅ‡¶ß‡ßÅ valid movie links ‡¶®‡ßá‡¶¨‡ßá
                    if self.is_movie_link(link_text, href):
                        movie_data = {
                            'title': self.clean_title(link_text),
                            'year': self.extract_year_from_text(link_text),
                            'quality': self.extract_quality_from_text(link_text),
                            'link': self.make_absolute_url(href)
                        }
                        
                        if movie_data['title'] and len(movie_data['title']) > 3:
                            self.movies_data.append(movie_data)
                            movie_count += 1
                            print(f"‚úÖ ‡¶Æ‡ßÅ‡¶≠‡¶ø {movie_count}: {movie_data['title']}")
                            
                except Exception as e:
                    continue
            
            # ‡¶Ø‡¶¶‡¶ø movie ‡¶®‡¶æ ‡¶™‡¶æ‡¶Ø‡¶º, ‡¶§‡¶æ‡¶π‡¶≤‡ßá headings ‡¶•‡ßá‡¶ï‡ßá ‡¶ñ‡ßÅ‡¶Å‡¶ú‡¶¨‡ßá
            if movie_count == 0:
                print("üîç ‡¶≤‡¶ø‡¶Ç‡¶ï ‡¶•‡ßá‡¶ï‡ßá ‡¶Æ‡ßÅ‡¶≠‡¶ø ‡¶®‡¶æ ‡¶™‡ßá‡¶Ø‡¶º‡ßá headings check ‡¶ï‡¶∞‡¶õ‡¶ø...")
                headings = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])
                for heading in headings:
                    try:
                        title = heading.text.strip()
                        if self.is_movie_title(title):
                            movie_data = {
                                'title': self.clean_title(title),
                                'year': self.extract_year_from_text(title),
                                'quality': self.extract_quality_from_text(title),
                                'link': self.website_url
                            }
                            
                            if movie_data['title'] and len(movie_data['title']) > 3:
                                self.movies_data.append(movie_data)
                                movie_count += 1
                                print(f"‚úÖ ‡¶Æ‡ßÅ‡¶≠‡¶ø {movie_count}: {movie_data['title']}")
                                
                    except Exception as e:
                        continue
            
            print(f"‚úÖ ‡¶∏‡ßç‡¶ï‡ßç‡¶∞‡ßá‡¶™‡¶ø‡¶Ç ‡¶∏‡¶Æ‡ßç‡¶™‡ßÇ‡¶∞‡ßç‡¶£: {movie_count} ‡¶ü‡¶ø ‡¶Æ‡ßÅ‡¶≠‡¶ø ‡¶™‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ ‡¶ó‡ßá‡¶õ‡ßá")
            return self.movies_data
            
        except Exception as e:
            print(f"‚ùå ‡¶∏‡ßç‡¶ï‡ßç‡¶∞‡ßá‡¶™‡¶ø‡¶Ç ‡¶è‡¶∞‡¶∞: {e}")
            return []

    def is_movie_link(self, link_text, href):
        """‡¶≤‡¶ø‡¶Ç‡¶ï‡¶ü‡¶ø ‡¶Æ‡ßÅ‡¶≠‡¶ø ‡¶≤‡¶ø‡¶Ç‡¶ï ‡¶ï‡¶ø‡¶®‡¶æ ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡¶¨‡ßá"""
        if not link_text or len(link_text) < 5:
            return False
        
        # Common non-movie texts exclude ‡¶ï‡¶∞‡¶¨‡ßá
        exclude_texts = ['home', 'login', 'facebook', 'telegram', 'twitter', 'instagram', 
                        'contact', 'about', 'privacy', 'terms', 'movie bazar', 'mbbd']
        
        if any(exclude in link_text.lower() for exclude in exclude_texts):
            return False
        
        # ‡¶∂‡ßÅ‡¶ß‡ßÅ valid-looking titles ‡¶®‡ßá‡¶¨‡ßá
        if len(link_text) > 20 and any(char.isdigit() for char in link_text):
            return True
            
        return len(link_text) > 10

    def is_movie_title(self, text):
        """‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü‡¶ü‡¶ø ‡¶Æ‡ßÅ‡¶≠‡¶ø ‡¶ü‡¶æ‡¶á‡¶ü‡ßá‡¶≤ ‡¶ï‡¶ø‡¶®‡¶æ ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡¶¨‡ßá"""
        if not text or len(text) < 10:
            return False
        
        # Common non-movie texts exclude ‡¶ï‡¶∞‡¶¨‡ßá
        exclude_texts = ['movie bazar', 'mbbd', 'home', 'login', 'welcome']
        
        if any(exclude in text.lower() for exclude in exclude_texts):
            return False
        
        return True

    def clean_title(self, title):
        """‡¶ü‡¶æ‡¶á‡¶ü‡ßá‡¶≤ ‡¶ï‡ßç‡¶≤‡¶ø‡¶® ‡¶ï‡¶∞‡¶¨‡ßá"""
        if not title:
            return ""
        
        # Extra spaces ‡¶è‡¶¨‡¶Ç newlines remove ‡¶ï‡¶∞‡¶¨‡ßá
        title = ' '.join(title.split())
        
        # Very long titles trim ‡¶ï‡¶∞‡¶¨‡ßá
        if len(title) > 100:
            title = title[:100] + "..."
            
        return title

    def extract_year_from_text(self, text):
        """‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü ‡¶•‡ßá‡¶ï‡ßá ‡¶∏‡¶æ‡¶≤ extract ‡¶ï‡¶∞‡¶¨‡ßá"""
        try:
            year_match = re.search(r'\b(20[0-2][0-9]|19[0-9]{2})\b', text)
            return year_match.group() if year_match else "2024"
        except:
            return "2024"

    def extract_quality_from_text(self, text):
        """‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü ‡¶•‡ßá‡¶ï‡ßá quality extract ‡¶ï‡¶∞‡¶¨‡ßá"""
        try:
            text_upper = text.upper()
            if any(q in text_upper for q in ['4K', 'UHD', '2160P']):
                return '4K'
            elif any(q in text_upper for q in ['1080P', 'FHD']):
                return '1080p'
            elif any(q in text_upper for q in ['720P', 'HD']):
                return '720p'
            else:
                return 'HD'
        except:
            return 'HD'

    def make_absolute_url(self, href):
        """Relative URL ‡¶ï‡ßá absolute URL-‡¶è convert ‡¶ï‡¶∞‡¶¨‡ßá"""
        if not href or href == '#':
            return self.website_url
            
        if href.startswith('http'):
            return href
        elif href.startswith('/'):
            return f"https://mbbd2.blogspot.com{href}"
        else:
            return f"https://mbbd2.blogspot.com/{href}"

# ‡¶ü‡ßá‡¶∏‡ßç‡¶ü ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø
if __name__ == "__main__":
    scraper = MovieScraper("https://mbbd2.blogspot.com/?m=0")
    movies = scraper.scrape_movies()
    
    if movies:
        print(f"\nüé¨ ‡¶∏‡ßç‡¶ï‡ßç‡¶∞‡ßá‡¶™ ‡¶ï‡¶∞‡¶æ ‡¶Æ‡ßÅ‡¶≠‡¶ø ‡¶≤‡¶ø‡¶∏‡ßç‡¶ü:")
        for i, movie in enumerate(movies[:10], 1):  # ‡¶∂‡ßÅ‡¶ß‡ßÅ ‡¶™‡ßç‡¶∞‡¶•‡¶Æ ‡ßß‡ß¶‡¶ü‡¶ø ‡¶¶‡ßá‡¶ñ‡¶æ‡¶¨‡ßá
            print(f"{i}. {movie['title']} ({movie['year']}) - {movie['quality']}")
        if len(movies) > 10:
            print(f"... ‡¶è‡¶¨‡¶Ç ‡¶Ü‡¶∞‡¶ì {len(movies) - 10} ‡¶ü‡¶ø ‡¶Æ‡ßÅ‡¶≠‡¶ø")
    else:
        print("‚ùå ‡¶ï‡ßã‡¶®‡ßã ‡¶Æ‡ßÅ‡¶≠‡¶ø ‡¶∏‡ßç‡¶ï‡ßç‡¶∞‡ßá‡¶™ ‡¶ï‡¶∞‡¶æ ‡¶Ø‡¶æ‡¶Ø‡¶º‡¶®‡¶ø")